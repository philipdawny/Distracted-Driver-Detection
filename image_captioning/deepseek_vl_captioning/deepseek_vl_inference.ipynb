{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b61b3d9c-a55f-4af4-966c-a8b23399e408",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting deepseek-vl\n",
      "  Downloading deepseek_vl-0.0.1.dev0-py3-none-any.whl.metadata (365 bytes)\n",
      "Downloading deepseek_vl-0.0.1.dev0-py3-none-any.whl (1.1 kB)\n",
      "Installing collected packages: deepseek-vl\n",
      "Successfully installed deepseek-vl-0.0.1.dev0\n"
     ]
    }
   ],
   "source": [
    "!pip install deepseek-vl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f05a65d6-4323-44da-8108-c4816955d984",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.chdir(r\"/nfs/home/tgv3756/dlproject/scripts/deepseek_vl/DeepSeek-VL2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cdb92065-9615-4e5d-823a-4e44eb3b89c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM\n",
    "import torch.multiprocessing as mp\n",
    "\n",
    "from deepseek_vl2.models import DeepseekVLV2Processor, DeepseekVLV2ForCausalLM\n",
    "from deepseek_vl2.utils.io import load_pil_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9bdbf546-4a09-41db-8018-0810d00d99b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.set_device(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "42f20401-f2f5-4cd2-9bad-b15d24f961fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "mp.set_start_method('spawn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "be013d8d-4ddd-475b-af9f-c883348834c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nfs/home/tgv3756/.local/lib/python3.9/site-packages/huggingface_hub/file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Add pad token = ['<｜▁pad▁｜>'] to the tokenizer\n",
      "<｜▁pad▁｜>:2\n",
      "Add image token = ['<image>'] to the tokenizer\n",
      "<image>:128815\n",
      "Add grounding-related tokens = ['<|ref|>', '<|/ref|>', '<|det|>', '<|/det|>', '<|grounding|>'] to the tokenizer with input_ids\n",
      "<|ref|>:128816\n",
      "<|/ref|>:128817\n",
      "<|det|>:128818\n",
      "<|/det|>:128819\n",
      "<|grounding|>:128820\n",
      "Add chat tokens = ['<|User|>', '<|Assistant|>'] to the tokenizer with input_ids\n",
      "<|User|>:128821\n",
      "<|Assistant|>:128822\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Loading DS VL2 tiny model\n",
    "\n",
    "model_path = \"deepseek-ai/deepseek-vl2-tiny\"\n",
    "vl_chat_processor: DeepseekVLV2Processor = DeepseekVLV2Processor.from_pretrained(model_path)\n",
    "tokenizer = vl_chat_processor.tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ced62856-4677-4e10-9748-562a8a5a124f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "vl_gpt: DeepseekVLV2ForCausalLM = AutoModelForCausalLM.from_pretrained(model_path, trust_remote_code=True)\n",
    "vl_gpt = vl_gpt.to(torch.bfloat16).cuda().eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "ebd616f1-3076-4088-a917-7ea1906a6834",
   "metadata": {},
   "outputs": [],
   "source": [
    "# conversation = [\n",
    "#     {\n",
    "#         \"role\": \"<|User|>\",\n",
    "#         \"content\": \"<image>\\n<|ref|>The driver is.<|/ref|>.\",\n",
    "#         \"images\": [\"/nfs/home/tgv3756/dlproject/data/imgs/train/c4/img_440.jpg\"],\n",
    "#     },\n",
    "#     {\"role\": \"<|Assistant|>\", \"content\": \"\"},\n",
    "# ]\n",
    "\n",
    "\n",
    "\n",
    "conversation = [\n",
    "    {\n",
    "        \"role\": \"<|User|>\",\n",
    "        \"content\": \"<image>\",\n",
    "        \"images\": [\"/nfs/home/tgv3756/dlproject/data/imgs/train/c6/img_678.jpg\"],\n",
    "    },\n",
    "    {\"role\": \"<|Assistant|>\", \"content\": \"\"},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "cb7bad2c-d1b1-4ed1-ba12-8c397b322266",
   "metadata": {},
   "outputs": [],
   "source": [
    "pil_images = load_pil_images(conversation)\n",
    "prepare_inputs = vl_chat_processor(\n",
    "    conversations=conversation,\n",
    "    images=pil_images,\n",
    "    force_batchify=True,\n",
    "    system_prompt=\"\"\n",
    ").to(vl_gpt.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "1f0d21a2-b473-4c32-b6f6-741aa8740fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_embeds = vl_gpt.prepare_inputs_embeds(**prepare_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "0ea28f7f-7d58-4763-acba-afdb45b716e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = vl_gpt.language.generate(\n",
    "    inputs_embeds=inputs_embeds,\n",
    "    attention_mask=prepare_inputs.attention_mask,\n",
    "    pad_token_id=tokenizer.eos_token_id,\n",
    "    bos_token_id=tokenizer.bos_token_id,\n",
    "    eos_token_id=tokenizer.eos_token_id,\n",
    "    max_new_tokens=512, ##512,\n",
    "    do_sample=True,\n",
    "    use_cache=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "5768d50d-4bd2-4cae-9a6a-554cb9dd3ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = tokenizer.decode(outputs[0].cpu().tolist(), skip_special_tokens=True) ##=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "40ab736c-57ff-47c6-91a7-44c966f1b364",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The man is drinking from his own water bottle while sitting in the driver's seat of his car. He appears calm but could be distracted by something happening outside or within the vehicle at that moment. The presence of a steering wheel indicates he has control over the vehicle currently. There doesn't seem to be any specific event occurring based solely on this snapshot; it looks like an ordinary scene where someone might drink during their commute or leisure time. It’s important for drivers to stay aware of traffic conditions and other road users when drinking beverages behind the wheel.\""
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2df6b2b3-f970-47e5-b209-ec22656671a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|User|>: <image>\n",
      "<|ref|>The driver is.<|/ref|>.\n",
      "\n",
      "<|Assistant|>: <|ref|>The driver is.<|/ref|><|det|>[[0, 0, 999, 999]]<|/det|><｜end▁of▁sentence｜>\n"
     ]
    }
   ],
   "source": [
    "print(f\"{prepare_inputs['sft_format'][0]}\", answer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
